{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/giggsy1106/DATA-622-NLP-/blob/main/NLPHW4_KOTA_FIXED.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60f208bd",
      "metadata": {
        "id": "60f208bd"
      },
      "source": [
        "# DATA 622 — Homework 4 (NLP)\n",
        "**Student:** Rahul Reddy Kota  \n",
        "\n",
        "This notebook completes the following NLP tasks using **spaCy** and **benepar** (constituency parsing):\n",
        "1. POS tagging (Sentence 1)\n",
        "2. Dependency parsing (Sentence 2)\n",
        "3. Constituency parsing (Sentence 1)\n",
        "4. Noun phrase extraction (Sentences 1 & 2)\n",
        "5. Short written comparison: **CRF vs HMM**\n",
        "\n",
        "---\n",
        "## Setup notes\n",
        "If you run this in **Google Colab**, use the setup cell below once, then **Runtime → Restart runtime**.\n",
        "If you run locally, use a virtual environment and install the same versions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d4c86d0",
      "metadata": {
        "id": "7d4c86d0",
        "outputId": "29805375-c3bc-4ca7-b914-a72b94f3aa30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Installing packages... (run once, then restart runtime)\n"
        }
      ],
      "source": [
        "# (Colab/First-time setup) Install compatible versions for benepar\n",
        "# After running, RESTART runtime/kernel before continuing.\n",
        "\n",
        "!pip -q uninstall -y transformers tokenizers\n",
        "!pip -q install transformers==4.17.0 benepar spacy nltk\n",
        "!python -m spacy download en_core_web_md\n",
        "!python -c \"import benepar; benepar.download('benepar_en3')\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93b03e9f",
      "metadata": {
        "id": "93b03e9f"
      },
      "source": [
        "## Step 1 — Load libraries, models, and input sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4add3b21",
        "outputId": "d5ba0fd1-c578-4f0d-d0f5-ed84e70b60fe"
      },
      "source": [
        "# ── Step 2: Imports ────────────────────────────────────────\n",
        "import spacy\n",
        "import benepar\n",
        "import nltk\n",
        "from nltk import Tree\n",
        "\n",
        "# ── Safe model download guard ────────────────────────────────\n",
        "benepar.download('benepar_en3')  # skips if already downloaded\n",
        "\n",
        "# ── Step 3: Load spaCy model and add benepar to pipeline ────\n",
        "nlp = spacy.load('en_core_web_md')\n",
        "if 'benepar' not in nlp.pipe_names:\n",
        "    nlp.add_pipe('benepar', config={'model': 'benepar_en3'})\n",
        "\n",
        "# ── Step 4: Define source text ───────────────────────────────\n",
        "sent1 = 'Four score and seven years ago our fathers brought forth on this continent, a new nation, conceived in Liberty, and dedicated to the proposition that all men are created equal.'\n",
        "sent2 = 'Now we are engaged in a great civil war, testing whether that nation, or any nation so conceived and so dedicated, can long endure.'\n",
        "\n",
        "doc1 = nlp(sent1)\n",
        "doc2 = nlp(sent2)\n",
        "\n",
        "s1 = list(doc1.sents)[0]\n",
        "s2 = list(doc2.sents)[0]\n",
        "print('Models loaded successfully.')\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Models loaded successfully.\n"
        }
      ],
      "id": "4add3b21"
    },
    {
      "cell_type": "markdown",
      "id": "87c96722",
      "metadata": {
        "id": "87c96722"
      },
      "source": [
        "## Task 2 — POS tagging (Sentence 1)\n",
        "Below we print each token, its coarse POS tag, and spaCy’s human-readable explanation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c91e11bd",
      "metadata": {
        "id": "c91e11bd",
        "outputId": "ced019c6-5a98-4a0d-c033-ab27fe78dfc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Token                     POS Tag    Description\n-------------------------------------------------------\nFour                      NUM        numeral\nscore                     NOUN       noun\nand                       CCONJ      coordinating conjunction\nseven                     NUM        numeral\nyears                     NOUN       noun\nago                       ADV        adverb\nour                       PRON       pronoun\nfathers                   NOUN       noun\nbrought                   VERB       verb\nforth                     ADV        adverb\non                        ADP        adposition\nthis                      DET        determiner\ncontinent                 NOUN       noun\n,                         PUNCT      punctuation\na                         DET        determiner\nnew                       ADJ        adjective\nnation                    NOUN       noun\n,                         PUNCT      punctuation\nconceived                 VERB       verb\nin                        ADP        adposition\nLiberty                   PROPN      proper noun\n,                         PUNCT      punctuation\nand                       CCONJ      coordinating conjunction\ndedicated                 VERB       verb\nto                        ADP        adposition\nthe                       DET        determiner\nproposition               NOUN       noun\nthat                      SCONJ      subordinating conjunction\nall                       DET        determiner\nmen                       NOUN       noun\nare                       AUX        auxiliary\ncreated                   VERB       verb\nequal                     ADJ        adjective\n.                         PUNCT      punctuation\n"
        }
      ],
      "source": [
        "# ============================================================\n",
        "# TASK 2: Part-of-Speech (POS) Tagging — Sentence 1 only\n",
        "# ============================================================\n",
        "\n",
        "# spaCy assigns POS tags based on the token's grammatical role\n",
        "# token.pos_ gives the coarse-grained tag (NOUN, VERB, ADJ, etc.)\n",
        "# spacy.explain() gives a human-readable description of the tag\n",
        "print(f\"{'Token':<25} {'POS Tag':<10} {'Description'}\")\n",
        "print(\"-\" * 55)\n",
        "for token in doc1:\n",
        "    print(f\"{token.text:<25} {token.pos_:<10} {spacy.explain(token.pos_)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8724c52",
      "metadata": {
        "id": "b8724c52"
      },
      "source": [
        "## Task 3 — Dependency parsing (Sentence 2)\n",
        "Below we show each token’s dependency relation and its head (governor) token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb5e62ca",
      "metadata": {
        "id": "eb5e62ca",
        "outputId": "6d3d2077-19b0-4ba8-e7ef-370f1fcd761b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Token                     Dependency           Head Word\n------------------------------------------------------------\nNow                       advmod               engaged\nwe                        nsubj                engaged\nare                       aux                  engaged\nengaged                   ROOT                 engaged\nin                        prep                 engaged\na                         det                  war\ngreat                     amod                 war\ncivil                     amod                 war\nwar                       pobj                 in\n,                         punct                war\ntesting                   advcl                engaged\nwhether                   mark                 endure\nthat                      det                  nation\nnation                    nsubj                endure\n,                         punct                nation\nor                        cc                   nation\nany                       det                  nation\nnation                    conj                 nation\nso                        advmod               conceived\nconceived                 relcl                nation\nand                       cc                   conceived\nso                        advmod               dedicated\ndedicated                 conj                 conceived\n,                         punct                nation\ncan                       aux                  endure\nlong                      advmod               endure\nendure                    ccomp                testing\n.                         punct                engaged\n"
        }
      ],
      "source": [
        "# ============================================================\n",
        "# TASK 3: Dependency Parsing — Sentence 2 only\n",
        "# ============================================================\n",
        "\n",
        "# Dependency parsing identifies grammatical relationships between tokens\n",
        "# token.dep_ = the dependency label (e.g., 'nsubj', 'dobj', 'prep')\n",
        "# token.head = the governor/head word this token is attached to\n",
        "print(f\"{'Token':<25} {'Dependency':<20} {'Head Word'}\")\n",
        "print(\"-\" * 60)\n",
        "for token in doc2:\n",
        "    print(f\"{token.text:<25} {token.dep_:<20} {token.head.text}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7839887c",
      "metadata": {
        "id": "7839887c"
      },
      "source": [
        "## Task 4 — Constituency parsing (Sentence 1)\n",
        "Benepar produces a Penn Treebank-style constituency parse. We render it using `nltk.Tree`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3b21a57",
        "outputId": "00576107-e8af-403f-dd63-3192f12f9c47"
      },
      "source": [
        "# ============================================================\n",
        "# TASK 4: Constituent (Phrase Structure) Parsing — Sentence 1\n",
        "# ============================================================\n",
        "\n",
        "parse_string = s1._.parse_string\n",
        "tree = Tree.fromstring(parse_string)\n",
        "\n",
        "print('── Constituency Parse Tree (Sentence 1) ──')\n",
        "print(parse_string)  # print bracket notation (always works in Colab)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "── Constituency Parse Tree (Sentence 1) ──\n(S\n  (NP\n    (NP (QP (CD Four) (NNS score) (CC and) (CD seven)) (NNS years))\n    (ADVP (RB ago)))\n  (NP (PRP$ our) (NNS fathers))\n  (VP (VBD brought)\n    (ADVP (RB forth))\n    (PP (IN on)\n      (NP (DT this) (NN continent)))\n    (, ,)\n    (NP\n      (NP (DT a) (JJ new) (NN nation))\n      (, ,)\n      (VP (VBN conceived)\n        (PP (IN in)\n          (NP (NNP Liberty))))\n      (, ,)\n      (CC and)\n      (VP (VBN dedicated)\n        (PP (IN to)\n          (NP\n            (NP (DT the) (NN proposition))\n            (SBAR (IN that)\n              (S\n                (NP (DT all) (NNS men))\n                (VP (VBP are)\n                  (VP (VBN created)\n                    (ADJP (JJ equal)))))))))))))\n  (. .))\n"
        }
      ],
      "id": "c3b21a57"
    },
    {
      "cell_type": "markdown",
      "id": "f49f4c8e",
      "metadata": {
        "id": "f49f4c8e"
      },
      "source": [
        "## Task 5 — Noun phrases (Sentences 1 & 2)\n",
        "We extract base noun phrases using spaCy’s `noun_chunks`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9b74a82",
      "metadata": {
        "id": "d9b74a82",
        "outputId": "699af888-31ca-4185-8130-6382974cab9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "── Noun Phrases in Sentence 1 ──\n  - Four score and seven years ago\n  - our fathers\n  - this continent\n  - a new nation\n  - Liberty\n  - the proposition\n  - all men\n\n── Noun Phrases in Sentence 2 ──\n  - we\n  - a great civil war\n  - that nation\n  - any nation\n"
        }
      ],
      "source": [
        "# ============================================================\n",
        "# TASK 5: Extract Noun Phrases — Both Sentences\n",
        "# ============================================================\n",
        "\n",
        "# spaCy's noun chunks are base noun phrases (NP) identified\n",
        "# using dependency parse information\n",
        "# Each chunk has: .text (the phrase), .root (the head noun),\n",
        "# .root.dep_ (its dependency label)\n",
        "print(\"── Noun Phrases in Sentence 1 ──\")\n",
        "for chunk in doc1.noun_chunks:\n",
        "    print(f\"  - {chunk.text}\")\n",
        "\n",
        "print(\"\\n── Noun Phrases in Sentence 2 ──\")\n",
        "for chunk in doc2.noun_chunks:\n",
        "    print(f\"  - {chunk.text}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d221555",
      "metadata": {
        "id": "1d221555"
      },
      "source": [
        "## Task 6 — CRF vs HMM (≤ 50 words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a5926df",
      "metadata": {
        "id": "1a5926df",
        "outputId": "fe8eb627-d5e7-41d6-f3e1-26670b4b3a79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "HMM is a generative sequence model that uses hidden states and emission probabilities, typically assuming limited independence between observations. CRF is a discriminative model that directly models P(labels|observations) and supports rich, overlapping features, often giving better accuracy for NER and POS tagging.\n\nWord count: 47\n"
        }
      ],
      "source": [
        "summary = \"\"\"HMM is a generative sequence model that uses hidden states and emission probabilities, typically assuming limited independence between observations. CRF is a discriminative model that directly models P(labels|observations) and supports rich, overlapping features, often giving better accuracy for NER and POS tagging.\"\"\"\n",
        "print(summary)\n",
        "print(\"\\nWord count:\", len(summary.split()))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}